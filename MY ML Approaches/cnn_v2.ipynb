{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"j4S0iaJuzOGW","outputId":"42f699a0-99d9-4a8e-efde-eac20ea31e1e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_8386/385959801.py:20: DeprecationWarning: Please import `pearsonr` from the `scipy.stats` namespace; the `scipy.stats.stats` namespace is deprecated and will be removed in SciPy 2.0.0.\n","  from scipy.stats.stats import pearsonr\n"]}],"source":["from __future__ import print_function\n","import numpy as np\n","import random\n","import pandas as pd\n","from scipy import stats\n","import sys, os\n","import logging\n","import tensorflow as tf\n","from keras import layers\n","from keras import regularizers\n","from keras.models import Model\n","from keras.models import Sequential\n","from keras.layers import *\n","from keras.regularizers import l1,l2, L1L2\n","from sklearn.metrics.pairwise import cosine_similarity\n","import keras\n","import keras.utils.np_utils as kutils\n","from keras.optimizers import SGD\n","from keras.callbacks import EarlyStopping,Callback,ModelCheckpoint,ReduceLROnPlateau\n","from scipy.stats.stats import pearsonr\n","from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn import datasets, linear_model\n","\n","import itertools\n","\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","import math as m\n","import keras.backend as K\n","import sklearn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4tbvuYozOGe"},"outputs":[],"source":["nb_classes = 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWdbxOlSzOGg"},"outputs":[],"source":["def indices_to_one_hot(data,nb_classes):\n","\n","\ttargets = np.array(data).reshape(-1)\n","\n","\treturn np.eye(nb_classes)[targets]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"em-1dwphzOGh"},"outputs":[],"source":["def readData(input):\n","    # Read the data\n","    data = pd.read_csv(input, sep='\\t', header=0, na_values='nan')\n","\n","    # Convert SNP, pheno, and folds columns to numeric\n","    SNP = data.iloc[:, 4:].apply(pd.to_numeric, errors='coerce').values\n","    pheno = pd.to_numeric(data.iloc[:, 1], errors='coerce').values\n","    folds = pd.to_numeric(data.iloc[:, 0], errors='coerce').values\n","\n","    # Check for missing values\n","    if data.isnull().values.any():\n","        print(\"Warning: Missing values found in the data.\")\n","\n","    # Initialize array to store one-hot encoded SNPs\n","    nb_classes = 4  # Adjust this according to the number of SNP categories\n","    arr = np.empty(shape=(SNP.shape[0], SNP.shape[1], nb_classes))\n","\n","    # Perform one-hot encoding for each SNP row\n","    for i in range(SNP.shape[0]):\n","        arr[i] = indices_to_one_hot(pd.to_numeric(SNP[i], downcast='signed'), nb_classes)\n","\n","    # Return the SNPs (one-hot encoded), phenotypes, and fold indices\n","    return arr, pheno, folds\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OwieRK_zOGj"},"outputs":[],"source":["def resnet(input):\n","\n","\tinputs = Input(shape=(input.shape[1],nb_classes))\n","\n","\n","\tx = Conv1D(10,4,padding='same',activation = 'linear',kernel_initializer = 'TruncatedNormal', kernel_regularizer=regularizers.l2(0.1),bias_regularizer = regularizers.l2(0.01))(inputs)\n","\n","\tx = Conv1D(10,20,padding='same',activation = 'linear', kernel_initializer = 'TruncatedNormal',kernel_regularizer=regularizers.l2(0.1),bias_regularizer = regularizers.l2(0.01))(x)\n","\n","\tx = Dropout(0.75)(x)\n","\n","\tshortcut = Conv1D(10,4,padding='same',activation = 'linear',kernel_initializer = 'TruncatedNormal', kernel_regularizer=regularizers.l2(0.1),bias_regularizer = regularizers.l2(0.01))(inputs)\n","\tx = layers.add([shortcut,x])\n","\n","\tx = Conv1D(10,4,padding='same',activation = 'linear',kernel_initializer = 'TruncatedNormal', kernel_regularizer=regularizers.l2(0.1),bias_regularizer = regularizers.l2(0.01))(x)\n","\n","\tx = Dropout(0.75)(x)\n","\tx = Flatten()(x)\n","\n","\tx = Dropout(0.75)(x)\n","\n","\toutputs = Dense(1,activation = isru,bias_regularizer = regularizers.l2(0.01),kernel_initializer = 'TruncatedNormal',name = 'out')(x)\n","\n","\tmodel = Model(inputs = inputs,outputs = outputs)\n","\tmodel.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=0.001),metrics=['mae'])\n","\n","\treturn model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6u45wl-zOGl"},"outputs":[],"source":["def compile_saliency_function(model):\n","\n","\tinp = model.layers[0].input\n","\toutp = model.layers[8].output\n","\tmax_outp = K.max(outp, axis=1)\n","\tsaliency = K.gradients(K.sum(max_outp), inp)\n","\n","\treturn K.function([inp,K.learning_phase()], saliency)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W54dDcbUzOGm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szSFOxI_zOGn"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def show_images_plot(saliency, outname):\n","    plt.figure(figsize=(15, 8), facecolor='w')\n","\n","    plt.subplot(2, 1, 1)\n","    x = np.median(saliency, axis=-1)\n","    plt.plot(x, 'b.')\n","    line = sorted(x, reverse=True)[10]\n","    plt.axhline(y=line, color='b', linestyle='--')\n","    plt.ylabel('Saliency Value', fontsize=15)\n","\n","    plt.subplot(2, 1, 2)\n","    plt.axhline(y=line, color='r', linestyle='--')\n","    plt.xlabel('SNPs', fontsize=15)\n","\n","    plt.savefig(outname)  # Save the plot\n","    plt.show()  # Display the plot\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fa15Z_3zOGp"},"outputs":[],"source":["def get_saliency(testSNP,model):\n","\n","\tarray= np.array([testSNP])\n","\tsaliency_fn = compile_saliency_function(model)\n","\tsaliency_out = saliency_fn([[y for y in array][0],1])\n","\tsaliency = saliency_out[0]\n","\tsaliency = saliency[::-1].transpose(1, 0, 2)\n","\toutput= np.abs(saliency).max(axis=-1)\n","\n","\treturn output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jua57b6bzOGr"},"outputs":[],"source":["a= 0.03  #height\n","\n","def isru(x):\n","    return  x/(K.sqrt(1+a*K.square(x)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b39FRlyPzOGs"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hzd_YMnMzOGs"},"outputs":[],"source":["def model_train(test,val,train,testPheno,valPheno,trainPheno,model_save,weights_save):\n","\n","\tbatch_size = 250\n","\tearlystop = 5\n","\tepoch = 300\n","\tearly_stopping = EarlyStopping(monitor='val_mean_absolute_error', patience=earlystop)\n","\n","\tmodel = resnet(train)\n","\thistory = model.fit(train, trainPheno, batch_size=batch_size, epochs=epoch, validation_data=(val,valPheno),callbacks=[early_stopping],shuffle= True)\n","\n","\tmodel.save(model_save)\n","\tmodel.save_weights(weights_save)\n","\n","\tpred = model.predict(test)\n","\tpred.shape = (pred.shape[0],)\n","\tcorr = pearsonr(pred,testPheno)[0]\n","\n","\treturn history,corr\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PX6SNXbTzOGt"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oYe6Q7wezOGu"},"outputs":[],"source":["def main(IMP_input,QA_input):\n","\n","\tIMP_corr=[]\n","\tQA_corr = []\n","\n","\timp_SNP,imp_pheno, folds = readData(IMP_input)\n","\tQA_SNP,QA_pheno, folds = readData(QA_input)\n","\n","\tPHENOTYPE = imp_pheno\n","\n","\tfor i in range(1,11):\n","\n","\t\ttestIdx = np.where(folds == i)\n","\t\tif i == 10:\n","\t\t\tvalIdx = np.where(folds == 1)\n","\t\t\ttrainIdx = np.intersect1d(np.where(folds != i),np.where(folds != 1))\n","\t\telse:\n","\t\t\tvalIdx = np.where(folds == i+1)\n","\t\t\ttrainIdx = np.intersect1d(np.where(folds != i),np.where(folds != i+1))\n","\n","\t\ttrainSNP, trainSNP_QA , trainPheno = imp_SNP[trainIdx], QA_SNP[trainIdx], PHENOTYPE[trainIdx]\n","\t\tvalSNP, valSNP_QA, valPheno = imp_SNP[valIdx],QA_SNP[valIdx], PHENOTYPE[valIdx]\n","\t\ttestSNP, testSNP_QA, testPheno = imp_SNP[testIdx],QA_SNP[testIdx], PHENOTYPE[testIdx]\n","\n","\t\tmodel_l = resnet(testSNP)\n","\t\tmodel_l.summary()\n","\t\t# Load the weights into the model\n","\t\tmodel_l.load_weights('model/model' + str(i) + '.h5')\n","\t\tprint(\"saliency output will be called \"+str(i))\n","\t\t# Get saliency map for test SNP using the trained model\n","\t\tsaliency_output = get_saliency(testSNP_QA, model_l)\n","\n","\t\toutname = 'My'+str(i)\n","\t\tshow_images_plot(saliency_output,outname)\n","\n","\t\thistory, corr = model_train(testSNP,valSNP,trainSNP,testPheno,valPheno,trainPheno,'out'+str(i)+'.txt','model_weights'+str(i)+'.h5')\n","\t\tIMP_corr.append(float('%0.4f' % corr))\n","\n","\t\thistory, corr = model_train(testSNP_QA,valSNP_QA,trainSNP_QA,testPheno,valPheno,trainPheno,'model_'+str(i)+'.txt','model_weights'+str(i)+'.h5')\n","\t\tQA_corr.append(float('%0.4f' % corr))\n","\n","\tprint (\"Average PCC (imputed) from 10-fold cross validation: \" + str(np.mean(IMP_corr)))\n","\tprint (\"Average PCC (non-imputed) from 10-fold cross validation: \" + str(np.mean(QA_corr)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"buBnoVL4zOGv"},"outputs":[],"source":["def MY_GRAPH(IMP_input, QA_input):\n","\n","    IMP_corr = []\n","    QA_corr = []\n","\n","    # Read input data\n","    imp_SNP, imp_pheno, folds = readData(IMP_input)\n","    QA_SNP, QA_pheno, folds = readData(QA_input)\n","\n","    PHENOTYPE = imp_pheno\n","\n","    for i in range(1, 11):\n","\n","        testIdx = np.where(folds == i)\n","        if i == 10:\n","            valIdx = np.where(folds == 1)\n","            trainIdx = np.intersect1d(np.where(folds != i), np.where(folds != 1))\n","        else:\n","            valIdx = np.where(folds == i+1)\n","            trainIdx = np.intersect1d(np.where(folds != i), np.where(folds != i+1))\n","\n","        # Split into training, validation, and testing sets\n","        trainSNP, trainSNP_QA, trainPheno = imp_SNP[trainIdx], QA_SNP[trainIdx], PHENOTYPE[trainIdx]\n","        valSNP, valSNP_QA, valPheno = imp_SNP[valIdx], QA_SNP[valIdx], PHENOTYPE[valIdx]\n","        testSNP, testSNP_QA, testPheno = imp_SNP[testIdx], QA_SNP[testIdx], PHENOTYPE[testIdx]\n","\n","        model_l = resnet(testSNP)\n","        model_l.summary()\n","# Load the weights into the model\n","        model_l.load_weights('model/model' + str(i) + '.h5')\n","        print(\"saliency output will be called \"+str(i))\n","        # Get saliency map for test SNP using the trained model\n","        saliency_output = get_saliency(testSNP, model_l)\n","\n","        outname = 'My'+str(i)\n","        show_images_plot(saliency_output,outname)\n","\n","\n","\n","        # Visualize saliency for each fold\n","#         plt.figure(figsize=(10, 6))\n","#         plt.imshow(saliency_output, cmap='hot', aspect='auto')\n","#         plt.colorbar()\n","#         plt.title(\"Saliency Map for Fold {}\".format(i))\n","#         plt.xlabel('SNP Features')\n","#         plt.ylabel('Samples')\n","#         plt.savefig('saliency_map_fold_{}.png'.format(i))  # Save the plot\n","#         plt.show()  # Display the plot\n","#         plt.pause(0.001)  # Pause to allow the plot to render\n","\n","\n","# #         Optionally, save or print the saliency output\n","#         print(\"Saliency output for fold {}:\".format(i))\n","#         print(saliency_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Bj3JQB2zOGw","outputId":"dd09f70a-a3e2-4d45-8ab7-2748fe6d9035"},"outputs":[{"name":"stdout","output_type":"stream","text":["['QA_Our_model_weights1.h5', 'My 8.png', 'model_weights1.h5', 'QA_Our_model_9.txt', 'model_2.txt', 'QA_Our_model_5.txt', 'our10.txt', 'QA_Our_model_weights5.h5', 'out8.txt', 'model', 'QA_Our_model_weights8.h5', 'model_1.txt', 'My 7.png', 'model_weights4.h5', 'QA_Our_model_7.txt', 'model_3.txt', 'QA_Our_model_weights9.h5', 'our6.txt', 'our3.txt', 'My5.png', 'QA_Our_model_3.txt', 'Our_model_weights8.h5', 'My 10.png', 'Our_model_weights5.h5', 'our2.txt', 'our1.txt', 'our9.txt', 'model_weights9.h5', 'Our_model_weights1.h5', 'model_weights3.h5', 'out10.txt', 'My 9.png', 'My4.png', 'model_10.txt', 'My 4.png', 'My8.png', 'Our_model_weights7.h5', 'model_weights7.h5', 'model_4.txt', 'polytest.txt', 'model_weights6.h5', 'our7.txt', 'model_weights2.h5', 'My1.png', 'model_6.txt', 'My 3.png', 'IMP_height.txt', 'model_8.txt', 'out6.txt', 'QA_Our_model_2.txt', 'QA_Our_model_weights2.h5', 'My 6.png', 'QA_Our_model_4.txt', 'My 2.png', 'Our_model_weights6.h5', 'model_5.txt', 'My3.png', 'model_weights8.h5', 'QA_Our_model_weights3.h5', 'out7.txt', 'Our_model_weights4.h5', 'model_9.txt', 'My 1.png', 'My7.png', 'model_weights5.h5', 'model_7.txt', 'our8.txt', 'QA_Our_model_weights7.h5', 'our4.txt', 'QA_Our_model_weights6.h5', 'Our_model_weights9.h5', 'QA_Our_model_weights10.h5', 'My 5.png', 'out5.txt', 'out4.txt', 'cnn_v1.ipynb', 'My10.png', 'My9.png', 'out2.txt', 'Our_model_weights10.h5', 'QA_Our_model_1.txt', 'QA_height.txt', '.ipynb_checkpoints', 'model_weights10.h5', 'out3.txt', 'our5.txt', 'QA_Our_model_10.txt', 'cnn_v2.ipynb', 'My2.png', 'Debug', 'Our_model_weights2.h5', 'QA_Our_model_weights4.h5', 'My6.png', 'QA_Our_model_6.txt', 'QA_Our_model_8.txt', 'out9.txt', 'Our_model_weights3.h5']\n"]}],"source":["import os\n","print(os.listdir('.'))  # This will show all files in the current directory\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Djxx4xUDzOGx","outputId":"48c78d0c-da32-49b2-d7c6-62be54af8a6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Result for trained model\n"]},{"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'convert_objects'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_8386/1126671898.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mIMP_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"IMP_height.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mQA_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"QA_height.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Result for trained model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mMY_GRAPH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMP_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQA_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#MY_GRAPH(IMP_input, QA_input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Call the MY_GRAPH function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_8386/2616553652.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(IMP_input, QA_input)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mIMP_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mQA_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Read input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimp_SNP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_pheno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMP_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mQA_SNP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQA_pheno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQA_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mPHENOTYPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp_pheno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_8386/3377053297.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mSNP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mpheno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/PR3_env1/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'convert_objects'"]}],"source":["\n","if __name__ == '__main__':\n","    # os.chdir(\"MOISTURE\")\n","\n","    IMP_input = \"IMP_height.txt\"\n","   # QA_input = \"QA_height.txt\"\n","    print(\"Result for trained model\")\n","    main(IMP_input,QA_input)\n","\n","    #MY_GRAPH(IMP_input, QA_input)\n","    # Call the MY_GRAPH function\n","\n"]}],"metadata":{"kernelspec":{"display_name":"PR3_env1","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}